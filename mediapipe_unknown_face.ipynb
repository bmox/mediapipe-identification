{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sbwN7gjO_RP9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install mediapipe\n",
        "!pip install bing-image-downloader\n",
        "!pip install deepface\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import math\n",
        "import csv "
      ],
      "metadata": {
        "id": "j18TvK11_xaC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title utils\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from deepface import DeepFace\n",
        "import math\n",
        "import time\n",
        "def deep_data_extract(img):\n",
        "    embedding=None\n",
        "    faces=[]\n",
        "    facial_data=[]\n",
        "    try:\n",
        "        embedding = DeepFace.represent(img, model_name='Facenet',detector_backend='ssd')\n",
        "        if embedding:\n",
        "          for  i in range(len(embedding)):\n",
        "            x, y, w, h = embedding[i]['facial_area']['x'], embedding[i]['facial_area']['y'], embedding[i]['facial_area']['w'], embedding[i]['facial_area']['h']\n",
        "            x1, y1, x2, y2 = x, y, x+w, y+h\n",
        "            faces.append((x1, y1, x2, y2 ))\n",
        "            facial_data.append(embedding[i]['embedding'])\n",
        "    except:\n",
        "        pass\n",
        "    return faces,facial_data\n",
        "\n",
        "\n",
        "def rgb_to_bgr(rgb_color):\n",
        "    bgr_color = (rgb_color[2], rgb_color[1], rgb_color[0])\n",
        "    return bgr_color\n",
        "    \n",
        "def drawBox(img, x1, y1, x2, y2, l=30, t=5, rt=1, text=\"Unknown\", id=None,display_id=False,draw_rect=False,color=(2, 240, 228),text_color=(255,255,255)):\n",
        "    # Define the sci-fi style font\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    fontScale = 0.7\n",
        "    thickness = 2\n",
        "    # color = (255, 255, 255)\n",
        "    color=rgb_to_bgr(color)\n",
        "    text_color=rgb_to_bgr(text_color)\n",
        "    # Draw the ID of the detected person on top of the bounding box\n",
        "    ((id_width, id_height), _) = cv2.getTextSize(str(id), font, fontScale=fontScale, thickness=thickness)\n",
        "    id_offset_x = x1 + int((x2 - x1 - id_width) / 2)\n",
        "    id_offset_y = y1 - 35\n",
        "    if display_id:\n",
        "        cv2.putText(img, str(id), (id_offset_x, id_offset_y+25), font, fontScale, text_color, thickness)\n",
        "        # Draw the name of the detected person inside the bounding box\n",
        "        ((text_width, text_height), _) = cv2.getTextSize(text, font, fontScale=fontScale, thickness=thickness)\n",
        "        text_offset_x = x1 + int((x2 - x1 - text_width) / 2)\n",
        "        text_offset_y = y2 + 25\n",
        "        cv2.putText(img, text, (text_offset_x, text_offset_y), font, fontScale, text_color, thickness)\n",
        "        # Draw box around face\n",
        "    if draw_rect:\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), color,thickness=rt)\n",
        "    t=t-3\n",
        "    face_width = x2 - x1\n",
        "    face_height = y2 - y1\n",
        "    # l = int(l * min(face_width, face_height) / 100)-20\n",
        "    \n",
        "    # Draw top-left corner\n",
        "    cv2.line(img, (x1, y1), (x1 + l, y1), color, thickness=t)\n",
        "    cv2.line(img, (x1, y1), (x1, y1 + l), color, thickness=t)\n",
        "    # Draw top-right corner\n",
        "    cv2.line(img, (x2, y1), (x2 - l, y1), color, thickness=t)\n",
        "    cv2.line(img, (x2, y1), (x2, y1 + l), color, thickness=t)\n",
        "    # Draw bottom-left corner\n",
        "    cv2.line(img, (x1, y2), (x1 + l, y2), color, thickness=t)\n",
        "    cv2.line(img, (x1, y2), (x1, y2 - l), color, thickness=t)\n",
        "    # Draw bottom-right corner\n",
        "    cv2.line(img, (x2, y2), (x2 - l, y2), color, thickness=t)\n",
        "    cv2.line(img, (x2, y2), (x2, y2 - l), color, thickness=t)\n",
        "    return img\n",
        "\n",
        "def white_overlay(img):\n",
        "    white_img = np.ones_like(img) * 255\n",
        "    alpha = 0.5\n",
        "    result = cv2.addWeighted(img, alpha, white_img, 1-alpha, 0)\n",
        "    x1 = 60\n",
        "    y1 = 60\n",
        "    x2 = img.shape[1] - 60\n",
        "    y2 = img.shape[0] - 60\n",
        "    mid_x = (img.shape[1]) // 2\n",
        "    roi = img[y1:y2, x1:x2]\n",
        "    result[y1:y2, x1:x2] = roi\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def fps_display(img,pTime):\n",
        "    mid_x = (img.shape[1]) // 2\n",
        "    fps = 0\n",
        "    cTime = time.time()\n",
        "    if cTime - pTime > 0:\n",
        "        fps = 1 / (cTime - pTime)\n",
        "    pTime = cTime\n",
        "    # text = f'FPS: {int(fps)}'\n",
        "    text=str(int(fps))\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "    font_scale = 3\n",
        "    thickness = 3\n",
        "    text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
        "    x = img.shape[1] - text_size[0] - 20\n",
        "    color=rgb_to_bgr((240, 0, 148))\n",
        "    cv2.putText(img, text, (mid_x, 45), font, font_scale,color, thickness)\n",
        "    return img,pTime\n",
        "\n",
        "\n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "NKf1KT3i_hlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75ef0b8-202b-4bb0-bac1-c8a0dc6b6351"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree(\"content/dataset\")\n",
        "!mkdir /content/dataset"
      ],
      "metadata": {
        "id": "sIoKJvQ3_pMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "if os.path.exists(\"./download\"):\n",
        "   shutil.rmtree(\"./download\")\n",
        "if not os.path.exists(\"./download\"):\n",
        "  os.mkdir(\"./download\")\n",
        "from bing_image_downloader import downloader\n",
        "def download_image(query,limit):\n",
        "  try:\n",
        "    downloader.download(query, limit=limit, output_dir='./download')\n",
        "  except:\n",
        "    pass\n",
        "celebrity_list=[\"boy\",\"men\",\"girls\"]\n",
        "for i in celebrity_list:\n",
        "  download_image(i,100)    \n",
        "\n",
        "clear_output()  "
      ],
      "metadata": {
        "id": "zIVJOdyP_8wd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import random\n",
        "def generate_name():\n",
        "  # Define the length of the file name\n",
        "  length = 8\n",
        "  # Define the set of characters to choose from\n",
        "  chars = string.ascii_letters + string.digits\n",
        "  # Generate a random file name\n",
        "  file_name = ''.join(random.choice(chars) for _ in range(length))\n",
        "  # Print the file name\n",
        "  return  file_name\n",
        "\n",
        "  \n",
        "if os.path.exists(\"./dataset\"):\n",
        "    shutil.rmtree(\"./dataset\")\n",
        "#     os.mkdir(\"./output\")\n",
        "if not os.path.exists(\"./dataset\"):\n",
        "    os.makedirs(\"./dataset\")\n",
        "\n",
        "for i in os.listdir(\"./download\"):\n",
        "  for j in os.listdir(f\"./download/{i}\"):\n",
        "    try:\n",
        "      extenstion=j.split(\".\")[-1]\n",
        "      shutil.copy(f\"./download/{i}/{j}\",f\"./dataset/{generate_name()}.{extenstion}\")\n",
        "    except:\n",
        "      pass    "
      ],
      "metadata": {
        "id": "UC2JkH9yASQd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(\"./dataset\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeR1RiE4Akno",
        "outputId": "4f89ff90-3abe-4540-ee08-1a35f05c0626"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "269"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def utils(img):\n",
        "  # cv2_imshow(img)\n",
        "  faces,facial_data=deep_data_extract(img)\n",
        "  if len(faces)!=0 and len(facial_data)!=0:\n",
        "    if len(faces)==len(facial_data):\n",
        "        return facial_data[0]\n",
        "  else:\n",
        "    return None\n",
        "        \n"
      ],
      "metadata": {
        "id": "jCghSK6GDkfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "def unknown_csv(face_data):\n",
        "    with open('unknown.csv', mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([face_data, \"unknown\",0,\"None\",\"None\"])"
      ],
      "metadata": {
        "id": "mWfgUfIkEAH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "for i in os.listdir(\"./dataset\"):\n",
        "  img=cv2.imread(f\"./dataset/{i}\")\n",
        "  try:\n",
        "    face_data=utils(img)\n",
        "    if face_data!=None:\n",
        "      print(face_data)\n",
        "      unknown_csv(face_data)\n",
        "  except:\n",
        "    pass\n",
        "clear_output()\n",
        "from google.colab import files\n",
        "files.download('/content/unknown.csv')"
      ],
      "metadata": {
        "id": "KXEWGRG7lJyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mediapipe==0.10.0"
      ],
      "metadata": {
        "id": "B-fyNIE49tSQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import mediapipe as mp\n",
        "\n",
        "BaseOptions = mp.tasks.BaseOptions\n",
        "ImageEmbedder = mp.tasks.vision.ImageEmbedder\n",
        "ImageEmbedderOptions = mp.tasks.vision.ImageEmbedderOptions\n",
        "VisionRunningMode = mp.tasks.vision.RunningMode"
      ],
      "metadata": {
        "id": "wA_jzqxU9piA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
        "    dim = None\n",
        "    (h, w) = image.shape[:2]\n",
        "    if width is None and height is None:\n",
        "        return image\n",
        "    if width is None:\n",
        "        r = height / float(h)\n",
        "        dim = (int(w * r), height)\n",
        "    else:\n",
        "        r = width / float(w)\n",
        "        dim = (width, int(h * r))\n",
        "    resized = cv2.resize(image, dim, interpolation = inter)\n",
        "    return resized\n"
      ],
      "metadata": {
        "id": "4Gz8YTW59uMg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcC7lTTP96Gq",
        "outputId": "2bb01b45-ea8c-4f58-e75b-5ed7d3aec93d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-01 17:18:29--  https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.31.128, 142.251.111.128, 142.251.163.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.31.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 229746 (224K) [application/octet-stream]\n",
            "Saving to: ‘blaze_face_short_range.tflite’\n",
            "\n",
            "\r          blaze_fac   0%[                    ]       0  --.-KB/s               \rblaze_face_short_ra 100%[===================>] 224.36K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-06-01 17:18:29 (98.0 MB/s) - ‘blaze_face_short_range.tflite’ saved [229746/229746]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_large/float32/latest/mobilenet_v3_large.tflite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peZDWK6p-ITb",
        "outputId": "8241c5e1-b867-4903-9dc5-de1396b31c19"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-01 17:19:27--  https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_large/float32/latest/mobilenet_v3_large.tflite\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.111.128, 142.251.163.128, 142.251.167.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10889458 (10M) [application/octet-stream]\n",
            "Saving to: ‘mobilenet_v3_large.tflite’\n",
            "\n",
            "mobilenet_v3_large. 100%[===================>]  10.38M  26.6MB/s    in 0.4s    \n",
            "\n",
            "2023-06-01 17:19:27 (26.6 MB/s) - ‘mobilenet_v3_large.tflite’ saved [10889458/10889458]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BaseOptions = mp.tasks.BaseOptions\n",
        "ImageEmbedder = mp.tasks.vision.ImageEmbedder\n",
        "ImageEmbedderOptions = mp.tasks.vision.ImageEmbedderOptions\n",
        "VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "new_options = ImageEmbedderOptions(\n",
        "    base_options=BaseOptions(model_asset_path='mobilenet_v3_large.tflite'),\n",
        "    l2_normalize=True,\n",
        "    quantize=True,\n",
        "    running_mode=VisionRunningMode.IMAGE)\n",
        "\n",
        "embedder=ImageEmbedder.create_from_options(new_options)\n",
        "def get_embadding(img):\n",
        "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=img)\n",
        "    embedding_result = embedder.embed(mp_image)\n",
        "    embedding_list = embedding_result.embeddings[0].embedding.tolist()\n",
        "    return embedding_list\n",
        "\n",
        "import csv\n",
        "import os\n",
        "def save_face_data_to_csv(face_data, ids, filename):\n",
        "    if not isinstance(face_data, list):\n",
        "        print(\"Error: face_data must be a list.\")\n",
        "        return\n",
        "    file_exists = os.path.exists(filename)\n",
        "    with open(filename, 'a' if file_exists else 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        if not file_exists:\n",
        "            writer.writerow([\"face_data\", \"id\"])\n",
        "        \n",
        "        writer.writerow([face_data, ids])\n",
        "    if file_exists:\n",
        "        pass \n",
        "        # print(f\"Face data appended to {filename} successfully.\")\n",
        "    else:\n",
        "        pass\n",
        "        # print(f\"Face data saved to {filename} successfully.\")\n",
        "    "
      ],
      "metadata": {
        "id": "_2lnMy3H9xby"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision"
      ],
      "metadata": {
        "id": "5jwccjoz9zZS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_options = python.BaseOptions(model_asset_path='blaze_face_short_range.tflite')\n",
        "options = vision.FaceDetectorOptions(base_options=base_options)\n",
        "detector = vision.FaceDetector.create_from_options(options)"
      ],
      "metadata": {
        "id": "2Rbky4aS-O5J"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_facial_data(IMAGE_FILE):\n",
        "    img = cv2.imread(IMAGE_FILE)\n",
        "    image = mp.Image(image_format=mp.ImageFormat.SRGB, data=img)\n",
        "    img = cv2.imread(IMAGE_FILE)\n",
        "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    detection_result = detector.detect(image)\n",
        "    if detection_result.detections:\n",
        "        for detection in detection_result.detections:\n",
        "            bbox = detection.bounding_box\n",
        "            x1, y1 = int(bbox.origin_x),int( bbox.origin_y)\n",
        "            x2, y2 = int(bbox.origin_x + bbox.width), int(bbox.origin_y + bbox.height)\n",
        "            x1, y1 = x1-20, y1-170\n",
        "            x2, y2 = x2+30, y2+130\n",
        "            # cv2.rectangle (img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            crop_img = img[y1:y2, x1:x2]\n",
        "            crop_img = image_resize(crop_img, width=480, height=480)\n",
        "            face_data=get_embadding(crop_img) \n",
        "            save_face_data_to_csv(face_data, 0, \"unknown.csv\")"
      ],
      "metadata": {
        "id": "_ZPMDt0h-S-I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"./dataset\"):"
      ],
      "metadata": {
        "id": "tcTq1Y6lAP2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "for i in os.listdir(\"./dataset\"):\n",
        "  try:\n",
        "        extract_facial_data(f\"./dataset/{i}\")\n",
        "  except:\n",
        "    pass\n",
        "  \n",
        "   "
      ],
      "metadata": {
        "id": "89yM9Kk89kAh"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}